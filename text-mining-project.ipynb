{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import wordnet, WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ DATASET AND CREATE TEXT AND TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Morgan Freeman 'Devastated' That Sexual Harass...</td>\n",
       "      <td>\"It is not right to equate horrific incidents ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Donald Trump Is Lovin' New McDonald's Jingle I...</td>\n",
       "      <td>It's catchy, all right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>What To Watch On Amazon Prime That’s New This ...</td>\n",
       "      <td>There's a great mini-series joining this week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Mike Myers Reveals He'd 'Like To' Do A Fourth ...</td>\n",
       "      <td>Myer's kids may be pushing for a new \"Powers\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>What To Watch On Hulu That’s New This Week</td>\n",
       "      <td>You're getting a recent Academy Award-winning ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "5  ENTERTAINMENT  Morgan Freeman 'Devastated' That Sexual Harass...   \n",
       "6  ENTERTAINMENT  Donald Trump Is Lovin' New McDonald's Jingle I...   \n",
       "7  ENTERTAINMENT  What To Watch On Amazon Prime That’s New This ...   \n",
       "8  ENTERTAINMENT  Mike Myers Reveals He'd 'Like To' Do A Fourth ...   \n",
       "9  ENTERTAINMENT         What To Watch On Hulu That’s New This Week   \n",
       "\n",
       "                                   short_description  \n",
       "0  She left her husband. He killed their children...  \n",
       "1                           Of course it has a song.  \n",
       "2  The actor and his longtime girlfriend Anna Ebe...  \n",
       "3  The actor gives Dems an ass-kicking for not fi...  \n",
       "4  The \"Dietland\" actress said using the bags is ...  \n",
       "5  \"It is not right to equate horrific incidents ...  \n",
       "6                            It's catchy, all right.  \n",
       "7     There's a great mini-series joining this week.  \n",
       "8  Myer's kids may be pushing for a new \"Powers\" ...  \n",
       "9  You're getting a recent Academy Award-winning ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json('data/News_Category_Dataset_v2.json', lines=True)\n",
    "\n",
    "# keep only text and target category\n",
    "dataset = dataset.drop(['date', 'link', 'authors'], axis=1)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (dataset['category'].map(lambda x: \"WORLDPOST\" if x == \"THE WORLDPOST\" else x)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIME', 'ENTERTAINMENT', 'ENTERTAINMENT', 'ENTERTAINMENT']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = (dataset['headline'] + ' ' + dataset['short_description']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV She left her husband. He killed their children. Just another day in America.',\n",
       " \"Will Smith Joins Diplo And Nicky Jam For The 2018 World Cup's Official Song Of course it has a song.\",\n",
       " 'Hugh Grant Marries For The First Time At Age 57 The actor and his longtime girlfriend Anna Eberstein tied the knot in a civil ceremony.',\n",
       " \"Jim Carrey Blasts 'Castrato' Adam Schiff And Democrats In New Artwork The actor gives Dems an ass-kicking for not fighting hard enough against Donald Trump.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TEXT CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patternAlphaNum = re.compile('[\\W_]+')\n",
    "stops = stopwords.words('english')\n",
    "wn = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# helper function to transform pos-tags\n",
    "# this is ridiculous btw\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return 'a'\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return 'v'\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return 'n'\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n'\n",
    "\n",
    "def clean_text(text, lemma_or_stem='lemma', word_transformer=wn, pattern=patternAlphaNum, stops=stops):\n",
    "    # split to words and lowercase\n",
    "    words = [word.lower() for word in text.split()]\n",
    "    \n",
    "    # keep only alphanumeric characters\n",
    "    words_alphanum = [pattern.sub('', word) for word in words]\n",
    "    \n",
    "    # remove stopwords\n",
    "    words_notstop = [word for word in words_alphanum if not ((word in stops) or (word == ''))]\n",
    "    \n",
    "    # lemmatize using pos tags\n",
    "    if lemma_or_stem == \"lemma\":\n",
    "        pos_tags = [get_wordnet_pos(pos[1]) for pos in pos_tag(words_notstop)]\n",
    "        return ' '.join([word_transformer.lemmatize(word, pos=pos_tag) for word, pos_tag in zip(words_notstop, pos_tags)])\n",
    "    \n",
    "    # stemming\n",
    "    elif lemma_or_stem == \"stem\":\n",
    "        return ' '.join([word_transformer.stem(word) for word in words_notstop])\n",
    "    \n",
    "    # return raw words\n",
    "    else:\n",
    "        return ' '.join(words_notstop)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_cleaned_lemma = [clean_text(text, 'lemma', wn) for text in tqdm(texts)]\n",
    "texts_cleaned_stem = [clean_text(text, 'stem', stemmer) for text in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine them to 1 text\n",
    "all_cleaned_text_lemma = '\\n'.join(texts_cleaned_lemma)\n",
    "all_cleaned_text_stem = '\\n'.join(texts_cleaned_stem)\n",
    "\n",
    "# write to file\n",
    "with open('cleaned_text/cleaned_text_lemma.txt', 'wb') as f:\n",
    "    f.write(all_cleaned_text_lemma.encode('utf-8'))\n",
    "with open('cleaned_text/cleaned_text_stem.txt', 'wb') as f:\n",
    "    f.write(all_cleaned_text_stem.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "with open('cleaned_text/cleaned_text_stem.txt', 'rb') as f:\n",
    "    all_cleaned_text_stem = [line.decode('utf-8').strip('\\n') for line in f.readlines()]\n",
    "with open('cleaned_text/cleaned_text_lemma.txt', 'rb') as f:\n",
    "    all_cleaned_text_lemma = [line.decode('utf-8').strip('\\n') for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata\n",
    "blobs = [TextBlob(text) for text in texts]\n",
    "polarities = [blob.polarity for blob in blobs]\n",
    "subjectivities = [blob.subjectivity for blob in blobs]\n",
    "lens = [len(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigram = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors_unigram = tfidf_unigram.fit_transform(all_cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors_unigram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigram.vocabulary_.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE UNION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
